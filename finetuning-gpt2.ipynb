{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-12-19T12:24:01.099277Z",
     "iopub.status.busy": "2024-12-19T12:24:01.099001Z",
     "iopub.status.idle": "2024-12-19T12:24:25.731268Z",
     "shell.execute_reply": "2024-12-19T12:24:25.730173Z",
     "shell.execute_reply.started": "2024-12-19T12:24:01.099257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install datasets torch peft scikit-learn\n",
    "pip install huggingface_hub==0.19.4\n",
    "pip install transformers==4.36.2\n",
    "pip install peft==0.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:47:34.575351Z",
     "iopub.status.busy": "2024-12-19T12:47:34.575042Z",
     "iopub.status.idle": "2024-12-19T12:47:34.579606Z",
     "shell.execute_reply": "2024-12-19T12:47:34.578881Z",
     "shell.execute_reply.started": "2024-12-19T12:47:34.575324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    GPT2ForSequenceClassification,\n",
    "    GPT2Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainerCallback\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:48:20.032497Z",
     "iopub.status.busy": "2024-12-19T12:48:20.032181Z",
     "iopub.status.idle": "2024-12-19T12:48:20.475729Z",
     "shell.execute_reply": "2024-12-19T12:48:20.474841Z",
     "shell.execute_reply.started": "2024-12-19T12:48:20.032471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "\n",
    "# Load dataset from JSONL file\n",
    "dataset = load_dataset('json', data_files='/kaggle/input/training/training.jsonl')['train']\n",
    "\n",
    "# Initialize label encoders\n",
    "sentiment_encoder = LabelEncoder()\n",
    "topic_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoders\n",
    "sentiments = dataset['sentiment']\n",
    "topics = dataset['topic']\n",
    "sentiment_encoder.fit(sentiments)\n",
    "topic_encoder.fit(topics)\n",
    "\n",
    "# Print unique labels and their counts\n",
    "print(\"Sentiment labels:\", sentiment_encoder.classes_)\n",
    "print(\"Topic labels:\", topic_encoder.classes_)\n",
    "n_sentiments = len(sentiment_encoder.classes_)\n",
    "n_topics = len(topic_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:48:20.032497Z",
     "iopub.status.busy": "2024-12-19T12:48:20.032181Z",
     "iopub.status.idle": "2024-12-19T12:48:20.475729Z",
     "shell.execute_reply": "2024-12-19T12:48:20.474841Z",
     "shell.execute_reply.started": "2024-12-19T12:48:20.032471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare dataset with one-hot encoded labels\n",
    "def prepare_dataset(examples):\n",
    "    # Create text inputs\n",
    "    texts = [f\"Review: {rev}\\nQuery: {q}\" for rev, q in zip(examples['review'], examples['query'])]\n",
    "    \n",
    "    # Convert labels to indices\n",
    "    sentiment_indices = sentiment_encoder.transform(examples['sentiment'])\n",
    "    topic_indices = topic_encoder.transform(examples['topic'])\n",
    "    \n",
    "    # Create combined one-hot labels\n",
    "    labels = np.zeros((len(texts), n_sentiments + n_topics))\n",
    "    for i, (s_idx, t_idx) in enumerate(zip(sentiment_indices, topic_indices)):\n",
    "        labels[i, s_idx] = 1  # Set sentiment one-hot\n",
    "        labels[i, n_sentiments + t_idx] = 1  # Set topic one-hot\n",
    "    \n",
    "    return {\n",
    "        'text': texts,\n",
    "        'labels': labels.tolist()  # Convert to list for dataset creation\n",
    "    }\n",
    "\n",
    "# Process the dataset\n",
    "processed_data = prepare_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:48:20.032497Z",
     "iopub.status.busy": "2024-12-19T12:48:20.032181Z",
     "iopub.status.idle": "2024-12-19T12:48:20.475729Z",
     "shell.execute_reply": "2024-12-19T12:48:20.474841Z",
     "shell.execute_reply.started": "2024-12-19T12:48:20.032471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split dataset indices\n",
    "indices = list(range(len(processed_data['text'])))\n",
    "train_idx, eval_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and eval datasets\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': [processed_data['text'][i] for i in train_idx],\n",
    "    'labels': [processed_data['labels'][i] for i in train_idx]\n",
    "})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    'text': [processed_data['text'][i] for i in eval_idx],\n",
    "    'labels': [processed_data['labels'][i] for i in eval_idx]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:48:32.354558Z",
     "iopub.status.busy": "2024-12-19T12:48:32.354263Z",
     "iopub.status.idle": "2024-12-19T12:48:32.774671Z",
     "shell.execute_reply": "2024-12-19T12:48:32.773849Z",
     "shell.execute_reply.started": "2024-12-19T12:48:32.354535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, padding_side='right')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Initialize model\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=n_sentiments + n_topics,  # Combined number of labels\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:48:32.354558Z",
     "iopub.status.busy": "2024-12-19T12:48:32.354263Z",
     "iopub.status.idle": "2024-12-19T12:48:32.774671Z",
     "shell.execute_reply": "2024-12-19T12:48:32.773849Z",
     "shell.execute_reply.started": "2024-12-19T12:48:32.354535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare model for QLoRA\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Configure LoRA\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"c_proj\", \"c_attn\"]\n",
    ")\n",
    "\n",
    "# Get PEFT model\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:48:50.750476Z",
     "iopub.status.busy": "2024-12-19T12:48:50.750170Z",
     "iopub.status.idle": "2024-12-19T12:48:58.301761Z",
     "shell.execute_reply": "2024-12-19T12:48:58.301007Z",
     "shell.execute_reply.started": "2024-12-19T12:48:50.750452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "# Tokenize datasets\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:48:50.750476Z",
     "iopub.status.busy": "2024-12-19T12:48:50.750170Z",
     "iopub.status.idle": "2024-12-19T12:48:58.301761Z",
     "shell.execute_reply": "2024-12-19T12:48:58.301007Z",
     "shell.execute_reply.started": "2024-12-19T12:48:50.750452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modified compute metrics function for multi-label classification\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = torch.sigmoid(torch.tensor(predictions)).numpy()\n",
    "    \n",
    "    # Split predictions and labels for sentiment and topic\n",
    "    sentiment_preds = predictions[:, :n_sentiments]\n",
    "    topic_preds = predictions[:, n_sentiments:]\n",
    "    \n",
    "    sentiment_labels = labels[:, :n_sentiments]\n",
    "    topic_labels = labels[:, n_sentiments:]\n",
    "    \n",
    "    # Get predicted classes\n",
    "    sentiment_pred_classes = np.argmax(sentiment_preds, axis=1)\n",
    "    topic_pred_classes = np.argmax(topic_preds, axis=1)\n",
    "    \n",
    "    # Get true classes\n",
    "    sentiment_true_classes = np.argmax(sentiment_labels, axis=1)\n",
    "    topic_true_classes = np.argmax(topic_labels, axis=1)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    sentiment_accuracy = (sentiment_pred_classes == sentiment_true_classes).mean()\n",
    "    topic_accuracy = (topic_pred_classes == topic_true_classes).mean()\n",
    "    \n",
    "    return {\n",
    "        \"sentiment_accuracy\": sentiment_accuracy,\n",
    "        \"topic_accuracy\": topic_accuracy,\n",
    "        \"average_accuracy\": (sentiment_accuracy + topic_accuracy) / 2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:48:58.303357Z",
     "iopub.status.busy": "2024-12-19T12:48:58.303025Z",
     "iopub.status.idle": "2024-12-19T12:48:58.337637Z",
     "shell.execute_reply": "2024-12-19T12:48:58.336950Z",
     "shell.execute_reply.started": "2024-12-19T12:48:58.303321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-qlora-classifier\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    disable_tqdm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:49:06.151375Z",
     "iopub.status.busy": "2024-12-19T12:49:06.151071Z",
     "iopub.status.idle": "2024-12-19T14:26:51.057020Z",
     "shell.execute_reply": "2024-12-19T14:26:51.056308Z",
     "shell.execute_reply.started": "2024-12-19T12:49:06.151351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom callback\n",
    "class TrainingCallback(TrainerCallback):\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        logging.info(f\"Starting training with {len(train_dataset)} examples\")\n",
    "        \n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        logging.info(f\"Starting epoch {state.epoch + 1}/{args.num_train_epochs}\")\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            if \"learning_rate\" in logs:\n",
    "                logging.info(f\"Learning Rate: {logs['learning_rate']:.2e}\")\n",
    "            if \"loss\" in logs:\n",
    "                logging.info(f\"Loss: {logs['loss']:.4f}\")\n",
    "            if \"eval_sentiment_accuracy\" in logs:\n",
    "                logging.info(f\"Sentiment Accuracy: {logs['eval_sentiment_accuracy']:.4f}\")\n",
    "            if \"eval_topic_accuracy\" in logs:\n",
    "                logging.info(f\"Topic Accuracy: {logs['eval_topic_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T12:49:06.151375Z",
     "iopub.status.busy": "2024-12-19T12:49:06.151071Z",
     "iopub.status.idle": "2024-12-19T14:26:51.057020Z",
     "shell.execute_reply": "2024-12-19T14:26:51.056308Z",
     "shell.execute_reply.started": "2024-12-19T12:49:06.151351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[TrainingCallback()]\n",
    ")\n",
    "\n",
    "# Print training details\n",
    "print(\"\\nTraining Configuration:\")\n",
    "print(f\"Number of training examples: {len(train_dataset)}\")\n",
    "print(f\"Number of evaluation examples: {len(eval_dataset)}\")\n",
    "print(f\"Number of sentiment classes: {n_sentiments}\")\n",
    "print(f\"Number of topic classes: {n_topics}\")\n",
    "print(f\"Number of epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Total optimization steps: {trainer.get_train_dataloader().__len__() * training_args.num_train_epochs}\\n\")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:26:51.058195Z",
     "iopub.status.busy": "2024-12-19T14:26:51.057914Z",
     "iopub.status.idle": "2024-12-19T14:26:52.267471Z",
     "shell.execute_reply": "2024-12-19T14:26:52.266825Z",
     "shell.execute_reply.started": "2024-12-19T14:26:51.058165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model(\"./gpt2-qlora-classifier-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:27:11.350781Z",
     "iopub.status.busy": "2024-12-19T14:27:11.350428Z",
     "iopub.status.idle": "2024-12-19T14:27:11.356264Z",
     "shell.execute_reply": "2024-12-19T14:27:11.355231Z",
     "shell.execute_reply.started": "2024-12-19T14:27:11.350750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modified prediction function\n",
    "def predict(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.sigmoid(logits)\n",
    "    \n",
    "    # Split predictions for sentiment and topic\n",
    "    sentiment_preds = predictions[0, :n_sentiments]\n",
    "    topic_preds = predictions[0, n_sentiments:]\n",
    "    \n",
    "    # Get predicted classes\n",
    "    sentiment_pred = sentiment_encoder.inverse_transform([torch.argmax(sentiment_preds).item()])[0]\n",
    "    topic_pred = topic_encoder.inverse_transform([torch.argmax(topic_preds).item()])[0]\n",
    "    \n",
    "    return {\n",
    "        \"sentiment\": sentiment_pred,\n",
    "        \"topic\": topic_pred,\n",
    "        \"sentiment_confidence\": torch.max(sentiment_preds).item(),\n",
    "        \"topic_confidence\": torch.max(topic_preds).item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:48:31.211537Z",
     "iopub.status.busy": "2024-12-19T14:48:31.211237Z",
     "iopub.status.idle": "2024-12-19T14:48:31.535670Z",
     "shell.execute_reply": "2024-12-19T14:48:31.534739Z",
     "shell.execute_reply.started": "2024-12-19T14:48:31.211514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "# Test with your own text\n",
    "your_text = \"Review: [this is truly something good] Query: [are they going to make anything different]\"\n",
    "result = predict(your_text)\n",
    "print(\"\\nInput:\", your_text)\n",
    "print(f\"Sentiment: {result['sentiment']} (Confidence: {result['sentiment_confidence']:.2f})\")\n",
    "print(f\"Topic: {result['topic']} (Confidence: {result['topic_confidence']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6336730,
     "sourceId": 10245921,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
